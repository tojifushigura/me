### **Методы оптимизации в машинном обучении**

Методы оптимизации — это алгоритмы, которые помогают моделям машинного обучения находить оптимальные параметры (например, веса), чтобы минимизировать ошибку (функцию потерь). Они определяют, как модель будет корректировать свои параметры на основе ошибок, чтобы лучше соответствовать данным.

---

### **Методы оптимизации**

1. **SGD (Stochastic Gradient Descent)**  
   - Это метод, который обновляет параметры модели на основе одной случайной выборки (или небольшого батча) данных за один раз.  
   - Процесс оптимизации проходит по небольшим шагам в направлении уменьшения ошибки.

2. **Adam (Adaptive Moment Estimation)**  
   - Более сложный метод, который адаптирует скорость обучения для каждого параметра, учитывая текущее и прошлое направление градиента.  
   - Использует комбинацию двух подходов: учета среднего значения градиентов и их изменения (момента).

3. **LBFGS (Limited-memory Broyden–Fletcher–Goldfarb–Shanno)**  
   - Метод оптимизации второго порядка, который приближает кривизну функции потерь (использует информацию о вторых производных).  
   - Более точный, но требует больше вычислений и памяти, чем SGD и Adam.

---

### **Таблица отличий**

| Характеристика           | **SGD**                         | **Adam**                                   | **LBFGS**                         |
|--------------------------|----------------------------------|-------------------------------------------|------------------------------------|
| **Тип оптимизации**      | Градиентный спуск               | Адаптивный градиентный спуск              | Второй порядок                    |
| **Данные для обновления**| Одна точка или мини-батч        | Мини-батч (адаптирует шаги для параметров)| Все данные (глобальная оптимизация)|
| **Скорость обучения**    | Постоянная или убывающая        | Адаптируется для каждого параметра        | Постоянная                        |
| **Память и вычисления**  | Легкий по ресурсам              | Умеренный                                | Требует больше памяти             |
| **Применение**           | Большие данные, онлайн-обучение | Сложные модели (нейросети)                | Малые и средние данные            |

Эти методы выбираются в зависимости от задачи, размера данных и доступных вычислительных ресурсов.
