Ваш код предназначен для выполнения задачи линейной и полиномиальной регрессии, а также регрессии с регуляризацией на наборе данных "Энергоэффективность" (Energy Efficiency) из UCI Machine Learning Repository. Давайте разберем каждую часть этого кода:

### Импорт библиотек

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from ucimlrepo import fetch_ucirepo
from sklearn.linear_model import LinearRegression, Ridge
from sklearn.preprocessing import PolynomialFeatures
from sklearn.metrics import mean_squared_error, r2_score
```

1. **numpy** (`np`) и **pandas** (`pd`): используются для работы с массивами и структурами данных.
2. **matplotlib.pyplot** (`plt`): для построения графиков.
3. **ucimlrepo.fetch_ucirepo**: библиотека для получения данных из репозитория UCI Machine Learning.
4. **sklearn.linear_model.LinearRegression** и **sklearn.linear_model.Ridge**: классы для выполнения линейной регрессии и Ridge-регрессии.
5. **PolynomialFeatures**: для преобразования данных в полиномиальные признаки.
6. **mean_squared_error** и **r2_score**: для оценки качества модели.

### Загрузка набора данных

```python
energy_efficiency = fetch_ucirepo(id=242)
X = energy_efficiency.data.features
y = energy_efficiency.data.targets
```

1. `fetch_ucirepo(id=242)`: загружает данные о энергоэффективности из UCI по ID.
2. `X` и `y`: соответственно признаки (независимые переменные) и целевые значения (зависимые переменные).

### 1. Разделение данных на обучающую и тестовую выборки

```python
np.random.seed(42)  # Для воспроизводимости
indices = np.random.permutation(len(X))
train_size = int(len(X) * 0.8)
train_indices = indices[:train_size]
test_indices = indices[train_size:]

X_train, X_test = X.iloc[train_indices], X.iloc[test_indices]
y_train, y_test = y.iloc[train_indices], y.iloc[test_indices]
```

1. `np.random.seed(42)`: фиксирует случайное начальное значение, чтобы данные разделялись одинаково при каждом запуске.
2. `indices`: создает перемешанный массив индексов.
3. `train_size`: вычисляет количество данных для обучения (80% от общего количества).
4. `train_indices` и `test_indices`: индексы для тренировочной и тестовой выборок.
5. `X_train`, `X_test`, `y_train`, `y_test`: деление данных на тренировочную и тестовую выборки.

### 2. Обучение модели линейной регрессии

```python
lin_reg = LinearRegression()
lin_reg.fit(X_train, y_train)

y_pred = lin_reg.predict(X_test)

mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Линейная регрессия: MSE = {mse:.2f}, R² = {r2:.2f}")
```

1. `lin_reg = LinearRegression()`: создание модели линейной регрессии.
2. `lin_reg.fit(X_train, y_train)`: обучение модели на тренировочных данных.
3. `y_pred = lin_reg.predict(X_test)`: предсказание на тестовой выборке.
4. `mse` и `r2`: вычисление средней квадратичной ошибки (MSE) и коэффициента детерминации (R²), которые оценивают точность модели.
5. `print`: выводит результаты.

### 3. Построение полиномиальной модели

```python
degrees = [1, 2, 3, 4, 5]
train_scores = []
test_scores = []

for degree in degrees:
    poly_features = PolynomialFeatures(degree=degree)
    X_poly_train = poly_features.fit_transform(X_train)
    X_poly_test = poly_features.transform(X_test)
    
    poly_reg = LinearRegression()
    poly_reg.fit(X_poly_train, y_train)
    
    train_pred = poly_reg.predict(X_poly_train)
    test_pred = poly_reg.predict(X_poly_test)
    
    train_scores.append(r2_score(y_train, train_pred))
    test_scores.append(r2_score(y_test, test_pred))
```

1. **Цикл по степеням `degrees`**: для построения модели с разными степенями полинома.
2. `poly_features`: трансформирует признаки в полиномиальные.
3. `X_poly_train`, `X_poly_test`: преобразованные тренировочные и тестовые данные.
4. `poly_reg.fit`, `poly_reg.predict`: обучение и предсказание для полиномиальной модели.
5. `train_scores` и `test_scores`: добавление оценок для каждой степени полинома.

#### Построение графика

```python
plt.figure(figsize=(10, 5))
plt.plot(degrees, train_scores, label='Train R²', marker='o')
plt.plot(degrees, test_scores, label='Test R²', marker='o')
plt.title('Точность полиномиальной регрессии в зависимости от степени полинома')
plt.xlabel('Степень полинома')
plt.ylabel('R²')
plt.legend()
plt.grid()
plt.show()
```

1. `plt.plot`: строит графики точности модели в зависимости от степени полинома.
2. `plt.legend`, `plt.grid`, `plt.show()`: настройка и отображение графика.

### 4. Модель с регуляризацией (Ridge Regression)

```python
ridge_train_scores = []
ridge_test_scores = []
alphas = np.logspace(-4, 4, 10)

for alpha in alphas:
    ridge_reg = Ridge(alpha=alpha)
    ridge_reg.fit(X_train, y_train)
    
    ridge_train_pred = ridge_reg.predict(X_train)
    ridge_test_pred = ridge_reg.predict(X_test)
    
    ridge_train_scores.append(r2_score(y_train, ridge_train_pred))
    ridge_test_scores.append(r2_score(y_test, ridge_test_pred))
```

1. **Цикл по `alphas`**: создает и оценивает модели Ridge-регрессии с разными коэффициентами регуляризации.
2. `ridge_reg`: создается модель с Ridge-регрессией.
3. `ridge_train_scores` и `ridge_test_scores`: сохраняет точности для тренировочной и тестовой выборок.

#### Построение графика зависимости от коэффициента регуляризации

```python
plt.figure(figsize=(10, 5))
plt.plot(alphas, ridge_train_scores, label='Train R²', marker='o')
plt.plot(alphas, ridge_test_scores, label='Test R²', marker='o')
plt.xscale('log')
plt.title('Точность Ridge-регрессии в зависимости от коэффициента регуляризации')
plt.xlabel('Коэффициент регуляризации (alpha)')
plt.ylabel('R²')
plt.legend()
plt.grid()
plt.show()
```

1. `plt.xscale('log')`: логарифмическая шкала по оси X для коэффициента регуляризации.
2. `plt.plot`: графики зависимости точности от коэффициента регуляризации.
