Вот краткое объяснение каждой концепции:

### Теория линейной регрессии
**Линейная регрессия** — это метод статистического анализа, используемый для моделирования зависимости между одной зависимой переменной \( y \) и одной или несколькими независимыми переменными \( x \). Основная цель линейной регрессии — найти наилучшую линейную функцию, которая предсказывает значения \( y \) на основе значений \( x \).

### Теория полиномиальной регрессии
**Полиномиальная регрессия** — это расширение линейной регрессии, в которой зависимость между переменной \( y \) и независимой переменной \( x \) моделируется в виде полинома более высокой степени.
В отличие от линейной регрессии, которая предполагает линейные зависимости, полиномиальная регрессия позволяет захватывать нелинейные зависимости. Она полезна в случаях, когда распределение данных является нелинейным, и простая линейная регрессия не может дать хорошие результаты. Однако при увеличении степени полинома появляется риск **переобучения**, когда модель слишком точно следует обучающей выборке, но плохо обобщает новые данные.

### Теория регуляризации и её виды
**Регуляризация** — это техника, используемая для уменьшения переобучения, добавляя штраф к модели за чрезмерную сложность. Регуляризация изменяет цель оптимизации, добавляя к функции потерь регуляризационный член, который контролирует величину коэффициентов модели. Существует несколько видов регуляризации:

1. **L2-регуляризация (Ridge-регрессия)**: добавляет штраф на сумму квадратов коэффициентов:
 Этот метод предотвращает чрезмерное увеличение коэффициентов, уменьшает дисперсию и часто используется для снижения коллинеарности.

2. **L1-регуляризация (Lasso-регрессия)**: добавляет штраф на сумму абсолютных значений коэффициентов:
 Она также уменьшает вес коэффициентов, но в отличие от Ridge-регрессии, может сводить некоторые из них к нулю, что автоматически выполняет отбор признаков, убирая несущественные параметры.

Регуляризация используется для улучшения обобщающей способности модели, уменьшая её склонность к переобучению и делая её более устойчивой к коллинеарности.

вычисление средней квадратичной ошибки (MSE) и коэффициента детерминации (R²)
-
Полиномиальная регрессия — это метод машинного обучения, который используется для моделирования нелинейных зависимостей между переменными. В отличие от линейной регрессии, которая предполагает линейную связь, полиномиальная регрессия позволяет учитывать более сложные, нелинейные отношения.
-
